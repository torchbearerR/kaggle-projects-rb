{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":477177,"sourceType":"datasetVersion","datasetId":216167}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Heart Disease Prediction - End-to-End ML Pipeline\n# -------------------------------------------------\n# Concepts: Binary classification, medical ML applications\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n\n# ==============================\n# Load Dataset\n# ==============================\n# Kaggle Dataset: https://www.kaggle.com/ronitf/heart-disease-uci\ndf = pd.read_csv(\"/kaggle/input/heart-disease-dataset/heart.csv\")\n\nprint(\"Shape:\", df.shape)\nprint(df.head())\n\n# ==============================\n# Features & Target\n# ==============================\nX = df.drop(\"target\", axis=1)\ny = df[\"target\"]\n\n# Split train/test\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# ==============================\n# Preprocessing (Scaling)\n# ==============================\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# ==============================\n# Models to Compare\n# ==============================\nmodels = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n    \"SVM (RBF Kernel)\": SVC(kernel=\"rbf\", probability=True, random_state=42),\n    \"Random Forest\": RandomForestClassifier(n_estimators=200, random_state=42),\n    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=200, learning_rate=0.05, random_state=42)\n}\n\n# ==============================\n# Train + Evaluate\n# ==============================\nresults = []\n\nfor name, model in models.items():\n    print(\"=\"*50)\n    print(f\"Model: {name}\")\n    \n    model.fit(X_train_scaled, y_train)\n    y_pred = model.predict(X_test_scaled)\n    y_prob = model.predict_proba(X_test_scaled)[:, 1]\n    \n    acc = accuracy_score(y_test, y_pred)\n    prec = precision_score(y_test, y_pred)\n    rec = recall_score(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred)\n    roc = roc_auc_score(y_test, y_prob)\n    \n    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n    print(\"Classification Report:\\n\", classification_report(y_test, y_pred, digits=4))\n    print(f\"Accuracy={acc:.4f}, Precision={prec:.4f}, Recall={rec:.4f}, F1={f1:.4f}, ROC-AUC={roc:.4f}\")\n    \n    results.append([name, acc, prec, rec, f1, roc])\n\n# ==============================\n# Results Summary\n# ==============================\nresults_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\", \"ROC-AUC\"])\nprint(\"\\nSummary of Model Performance:\\n\", results_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T12:59:07.337469Z","iopub.execute_input":"2025-09-03T12:59:07.337874Z","iopub.status.idle":"2025-09-03T12:59:10.232005Z","shell.execute_reply.started":"2025-09-03T12:59:07.337846Z","shell.execute_reply":"2025-09-03T12:59:10.230892Z"}},"outputs":[{"name":"stdout","text":"Shape: (1025, 14)\n   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n0   52    1   0       125   212    0        1      168      0      1.0      2   \n1   53    1   0       140   203    1        0      155      1      3.1      0   \n2   70    1   0       145   174    0        1      125      1      2.6      0   \n3   61    1   0       148   203    0        1      161      0      0.0      2   \n4   62    0   0       138   294    1        1      106      0      1.9      1   \n\n   ca  thal  target  \n0   2     3       0  \n1   0     3       0  \n2   0     3       0  \n3   1     3       0  \n4   3     2       0  \n==================================================\nModel: Logistic Regression\nConfusion Matrix:\n [[70 30]\n [ 9 96]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.8861    0.7000    0.7821       100\n           1     0.7619    0.9143    0.8312       105\n\n    accuracy                         0.8098       205\n   macro avg     0.8240    0.8071    0.8066       205\nweighted avg     0.8225    0.8098    0.8072       205\n\nAccuracy=0.8098, Precision=0.7619, Recall=0.9143, F1=0.8312, ROC-AUC=0.9298\n==================================================\nModel: SVM (RBF Kernel)\nConfusion Matrix:\n [[91  9]\n [ 6 99]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.9381    0.9100    0.9239       100\n           1     0.9167    0.9429    0.9296       105\n\n    accuracy                         0.9268       205\n   macro avg     0.9274    0.9264    0.9267       205\nweighted avg     0.9271    0.9268    0.9268       205\n\nAccuracy=0.9268, Precision=0.9167, Recall=0.9429, F1=0.9296, ROC-AUC=0.9771\n==================================================\nModel: Random Forest\nConfusion Matrix:\n [[100   0]\n [  0 105]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     1.0000    1.0000    1.0000       100\n           1     1.0000    1.0000    1.0000       105\n\n    accuracy                         1.0000       205\n   macro avg     1.0000    1.0000    1.0000       205\nweighted avg     1.0000    1.0000    1.0000       205\n\nAccuracy=1.0000, Precision=1.0000, Recall=1.0000, F1=1.0000, ROC-AUC=1.0000\n==================================================\nModel: Gradient Boosting\nConfusion Matrix:\n [[ 97   3]\n [  3 102]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0     0.9700    0.9700    0.9700       100\n           1     0.9714    0.9714    0.9714       105\n\n    accuracy                         0.9707       205\n   macro avg     0.9707    0.9707    0.9707       205\nweighted avg     0.9707    0.9707    0.9707       205\n\nAccuracy=0.9707, Precision=0.9714, Recall=0.9714, F1=0.9714, ROC-AUC=0.9879\n\nSummary of Model Performance:\n                  Model  Accuracy  Precision    Recall        F1   ROC-AUC\n0  Logistic Regression  0.809756   0.761905  0.914286  0.831169  0.929810\n1     SVM (RBF Kernel)  0.926829   0.916667  0.942857  0.929577  0.977143\n2        Random Forest  1.000000   1.000000  1.000000  1.000000  1.000000\n3    Gradient Boosting  0.970732   0.971429  0.971429  0.971429  0.987905\n","output_type":"stream"}],"execution_count":1}]}